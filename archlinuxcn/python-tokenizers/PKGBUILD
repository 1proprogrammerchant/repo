# Maintainer: Butui Hu <hot123tea123@gmail.com>

_pkgname=tokenizers
pkgname=python-tokenizers
pkgver=0.11.3
pkgrel=1
pkgdesc='Fast State-of-the-Art Tokenizers optimized for Research and Production'
arch=('x86_64')
url='https://github.com/huggingface/tokenizers'
license=('Apache')
depends=(
  python
)
makedepends=(
  python-setuptools-rust
)

source=("${_pkgname}-${pkgver}.tar.gz::https://files.pythonhosted.org/packages/source/${_pkgname::1}/${_pkgname}/${_pkgname}-${pkgver}.tar.gz")
sha512sums=('5acd9f4897be63e0cb0908a3f4663164e8c85ebbfc5c0a97830d1f67808d070a939c895124c49a01a5b84c0cd812ccc715eaf47e290b969c5972bb6645d765d8')

build() {
  cd "${_pkgname}-${pkgver}"
  python setup.py build
}

package() {
  cd "${_pkgname}-${pkgver}"
  python setup.py install --root="${pkgdir}" --optimize=1
}
# vim:set ts=2 sw=2 et:
