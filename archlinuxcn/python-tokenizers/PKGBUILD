# Maintainer: Butui Hu <hot123tea123@gmail.com>

_pkgname=tokenizers
pkgname=python-tokenizers
pkgver=0.11.1
pkgrel=1
pkgdesc='Fast State-of-the-Art Tokenizers optimized for Research and Production'
arch=('x86_64')
url='https://github.com/huggingface/tokenizers'
license=('Apache')
depends=(
  python
)
makedepends=(
  python-setuptools-rust
)

source=("${_pkgname}-${pkgver}.tar.gz::https://files.pythonhosted.org/packages/source/${_pkgname::1}/${_pkgname}/${_pkgname}-${pkgver}.tar.gz")
sha512sums=('1a1e7529663c3679c27312fdb5e090fd4b26aba603600db709c900c3cdb7781af0a720acf6009420c31bb74993ebb185ea1c0ed9a0633989473b1c3b4b6be29c')

build() {
  cd "${_pkgname}-${pkgver}"
  python setup.py build
}

package() {
  cd "${_pkgname}-${pkgver}"
  python setup.py install --root="${pkgdir}" --optimize=1
}
# vim:set ts=2 sw=2 et:
