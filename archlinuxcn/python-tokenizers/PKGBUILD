# Maintainer: Butui Hu <hot123tea123@gmail.com>

_pkgname=tokenizers
pkgname=python-tokenizers
pkgver=0.12.0
pkgrel=1
pkgdesc='Fast State-of-the-Art Tokenizers optimized for Research and Production'
arch=('x86_64')
url='https://github.com/huggingface/tokenizers'
license=('Apache')
depends=(
  python
)
makedepends=(
  python-setuptools-rust
)

source=("${_pkgname}-${pkgver}.tar.gz::https://files.pythonhosted.org/packages/source/${_pkgname::1}/${_pkgname}/${_pkgname}-${pkgver}.tar.gz")
sha512sums=('126cad9e2177d2e2d57d722879e5a146025847ae47497213347e1e1c154f59093488699cd16136a618cfd9eb8ecfa2b2fbc98a60a5222a135322af9d711664ae')

build() {
  cd "${_pkgname}-${pkgver}"
  python setup.py build
}

package() {
  cd "${_pkgname}-${pkgver}"
  python setup.py install --root="${pkgdir}" --optimize=1
}
# vim:set ts=2 sw=2 et:
